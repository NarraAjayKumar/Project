{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8d64d3",
   "metadata": {},
   "source": [
    "First, install the Roboflow SDK\n",
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e471c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Initialize Roboflow with your API key\n",
    "rf = Roboflow(api_key=\"79dhzfFvs8UNcpV3EWLU\")\n",
    "\n",
    "# Access the specific project and version in the Roboflow workspace\n",
    "project = rf.workspace(\"diabetic-retinopathy-efigv\").project(\"diabetic-retinopathy-hvhiu\")\n",
    "\n",
    "# Access the specific version of the project\n",
    "version = project.version(1)\n",
    "\n",
    "# Download the dataset in \"multiclass\" format\n",
    "dataset = version.download(\"multiclass\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f48339",
   "metadata": {},
   "source": [
    " importing all the necessary libraries and modules to build, train, and optimize a deep learning model for image classification, diabetic retinopathy detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f105c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Data Summary:\n",
      "Classes: [' Advanced', ' Cotton Wool Spot', ' Hard Exudates', ' Hemorrhages', ' Micro-aneurysms', ' Moderate', ' Moderate DR', ' NPDR', ' No DR', ' PDR', ' Severe', ' Severe  DR', ' Severe DR', ' Soft Cotton Wool', ' Soft Exudates', ' Very', ' hemorrhages']\n",
      "Train samples: 241\n",
      "Validation samples: 71\n",
      "Test samples: 36\n",
      "\n",
      "Creating data generators...\n",
      "Found 241 validated image filenames.\n",
      "Found 71 validated image filenames.\n",
      "Found 36 validated image filenames.\n",
      "\n",
      "Creating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,425</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,311,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)             │        \u001b[38;5;34m17,425\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,378,740</span> (20.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,378,740\u001b[0m (20.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,169</span> (5.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,329,169\u001b[0m (5.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0524 - auc: 0.5782 - loss: 0.6365\n",
      "Epoch 1: val_loss improved from inf to 0.48914, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.0577 - auc: 0.5850 - loss: 0.6313 - val_accuracy: 0.1268 - val_auc: 0.7880 - val_loss: 0.4891 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1557 - auc: 0.7897 - loss: 0.4707\n",
      "Epoch 2: val_loss improved from 0.48914 to 0.39358, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1578 - auc: 0.7909 - loss: 0.4680 - val_accuracy: 0.1268 - val_auc: 0.8269 - val_loss: 0.3936 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1690 - auc: 0.8303 - loss: 0.3869\n",
      "Epoch 3: val_loss improved from 0.39358 to 0.34825, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1696 - auc: 0.8303 - loss: 0.3856 - val_accuracy: 0.1268 - val_auc: 0.8352 - val_loss: 0.3483 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1707 - auc: 0.8330 - loss: 0.3427\n",
      "Epoch 4: val_loss improved from 0.34825 to 0.32919, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.1711 - auc: 0.8337 - loss: 0.3426 - val_accuracy: 0.1268 - val_auc: 0.8408 - val_loss: 0.3292 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1676 - auc: 0.8580 - loss: 0.3248\n",
      "Epoch 5: val_loss improved from 0.32919 to 0.32021, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1683 - auc: 0.8564 - loss: 0.3250 - val_accuracy: 0.1268 - val_auc: 0.8408 - val_loss: 0.3202 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1597 - auc: 0.8410 - loss: 0.3265\n",
      "Epoch 6: val_loss improved from 0.32021 to 0.31471, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1609 - auc: 0.8419 - loss: 0.3257 - val_accuracy: 0.1268 - val_auc: 0.8417 - val_loss: 0.3147 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2013 - auc: 0.8307 - loss: 0.3159\n",
      "Epoch 7: val_loss improved from 0.31471 to 0.31195, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1983 - auc: 0.8322 - loss: 0.3160 - val_accuracy: 0.1268 - val_auc: 0.8430 - val_loss: 0.3119 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1529 - auc: 0.8549 - loss: 0.3095\n",
      "Epoch 8: val_loss improved from 0.31195 to 0.31095, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.1543 - auc: 0.8541 - loss: 0.3101 - val_accuracy: 0.1268 - val_auc: 0.8414 - val_loss: 0.3110 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1940 - auc: 0.8477 - loss: 0.3083\n",
      "Epoch 9: val_loss improved from 0.31095 to 0.30945, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1918 - auc: 0.8477 - loss: 0.3090 - val_accuracy: 0.1268 - val_auc: 0.8418 - val_loss: 0.3095 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2153 - auc: 0.8548 - loss: 0.3132\n",
      "Epoch 10: val_loss improved from 0.30945 to 0.30907, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.2107 - auc: 0.8540 - loss: 0.3132 - val_accuracy: 0.1268 - val_auc: 0.8426 - val_loss: 0.3091 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1829 - auc: 0.8389 - loss: 0.3154\n",
      "Epoch 11: val_loss improved from 0.30907 to 0.30856, saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1820 - auc: 0.8399 - loss: 0.3151 - val_accuracy: 0.1268 - val_auc: 0.8413 - val_loss: 0.3086 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1977 - auc: 0.8582 - loss: 0.3102\n",
      "Epoch 12: val_loss did not improve from 0.30856\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.1946 - auc: 0.8569 - loss: 0.3105 - val_accuracy: 0.1268 - val_auc: 0.8412 - val_loss: 0.3096 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1544 - auc: 0.8526 - loss: 0.3143 \n",
      "Epoch 13: val_loss did not improve from 0.30856\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1566 - auc: 0.8521 - loss: 0.3142 - val_accuracy: 0.1268 - val_auc: 0.8411 - val_loss: 0.3086 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1945 - auc: 0.8532 - loss: 0.3121\n",
      "Epoch 14: val_loss did not improve from 0.30856\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1918 - auc: 0.8526 - loss: 0.3122 - val_accuracy: 0.1268 - val_auc: 0.8416 - val_loss: 0.3093 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1050 - auc: 0.8500 - loss: 0.3145\n",
      "Epoch 15: val_loss did not improve from 0.30856\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.1099 - auc: 0.8499 - loss: 0.3143 - val_accuracy: 0.1268 - val_auc: 0.8412 - val_loss: 0.3092 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1611 - auc: 0.8700 - loss: 0.3040\n",
      "Epoch 16: val_loss did not improve from 0.30856\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1607 - auc: 0.8676 - loss: 0.3049 - val_accuracy: 0.1268 - val_auc: 0.8417 - val_loss: 0.3093 - learning_rate: 1.0000e-05\n",
      "Epoch 16: early stopping\n",
      "\n",
      "Evaluating on test set...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.1447 - auc: 0.9029 - loss: 0.2911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Evaluation:\n",
      "Loss: 0.2929\n",
      "Accuracy: 0.1389\n",
      "AUC: 0.9015\n",
      "\n",
      "Saving model to C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\diabetic_retinopathy_model.h5\n",
      "\n",
      "Making sample prediction for: C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic\\DIABETIC-RETINOPATHY-1\\test\\313_jpg.rf.39db4e4d483f6f3d39c344a8d395210b.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Prediction results:\n",
      " Advanced: 0.14 (Absent)\n",
      " Cotton Wool Spot: 0.01 (Absent)\n",
      " Hard Exudates: 0.26 (Absent)\n",
      " Hemorrhages: 0.20 (Absent)\n",
      " Micro-aneurysms: 0.50 (Absent)\n",
      " Moderate: 0.01 (Absent)\n",
      " Moderate DR: 0.10 (Absent)\n",
      " NPDR: 0.03 (Absent)\n",
      " No DR: 0.13 (Absent)\n",
      " PDR: 0.24 (Absent)\n",
      " Severe: 0.03 (Absent)\n",
      " Severe  DR: 0.01 (Absent)\n",
      " Severe DR: 0.49 (Absent)\n",
      " Soft Cotton Wool: 0.44 (Absent)\n",
      " Soft Exudates: 0.01 (Absent)\n",
      " Very: 0.01 (Absent)\n",
      " hemorrhages: 0.01 (Absent)\n"
     ]
    }
   ],
   "source": [
    "import os  # Used for interacting with the operating system, like file paths and directories.\n",
    "import pandas as pd  # Used for reading and handling data in tabular form (CSV, Excel, etc.).\n",
    "import numpy as np  # Used for numerical operations and handling arrays.\n",
    "import cv2  # OpenCV library used for image processing tasks.\n",
    "import tensorflow as tf  # Imports TensorFlow, the deep learning framework.\n",
    "from tensorflow.keras.applications import EfficientNetB0  # Imports a pre-trained EfficientNetB0 model for transfer learning.\n",
    "from tensorflow.keras.models import Model, load_model  # Used to define custom models and load saved models.\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D  # Layers used to modify and extend the pre-trained model.\n",
    "from tensorflow.keras.optimizers import Adam  # Imports the Adam optimizer for training the model.\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau  # Callbacks to improve training (stop early, save best model, adjust learning rate).\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Used for real-time data augmentation and preprocessing.\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224, 224)  # Target size of input images\n",
    "BATCH_SIZE = 32  # Number of samples processed before model update\n",
    "EPOCHS = 50  # Number of complete passes through the training dataset\n",
    "LEARNING_RATE = 0.0001  # Learning rate for optimizer\n",
    "MODEL_SAVE_PATH = 'C:\\\\Users\\\\narra\\\\OneDrive\\\\Desktop\\\\My personal Files\\\\MY projects\\\\diabetic_retinopathy_app\\\\diabetic_retinopathy_app\\\\diabetic_retinopathy_model.h5'  # Path to save the trained model\n",
    "\n",
    "# 1. Data Preparation\n",
    "def load_data():\n",
    "    \"\"\"Load data from your exact folder structure\"\"\"\n",
    "    base_path = r'C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic\\DIABETIC-RETINOPATHY-1'  # Root directory for dataset\n",
    "\n",
    "    # Load CSV Files\n",
    "    train_df = pd.read_csv(os.path.join(base_path, 'train', '_classes.csv'))  # Load training data CSV\n",
    "    test_df = pd.read_csv(os.path.join(base_path, 'test', '_classes.csv'))  # Load testing data CSV\n",
    "    valid_df = pd.read_csv(os.path.join(base_path, 'valid', '_classes.csv'))  # Load validation data CSV\n",
    "\n",
    "    # Create full image paths (images are in same folder as CSVs)\n",
    "    train_df['full_path'] = train_df['filename'].apply(lambda x: os.path.join(base_path, 'train', x))  # Add full image path for training data\n",
    "    test_df['full_path'] = test_df['filename'].apply(lambda x: os.path.join(base_path, 'test', x))  # Add full image path for testing data\n",
    "    valid_df['full_path'] = valid_df['filename'].apply(lambda x: os.path.join(base_path, 'valid', x))  # Add full image path for validation data\n",
    "\n",
    "    # Verify all images exist\n",
    "    for name, df in [('Train', train_df), ('Test', test_df), ('Valid', valid_df)]:\n",
    "        df['exists'] = df['full_path'].apply(lambda x: os.path.exists(x))  # Check if image file exists\n",
    "        missing = len(df[~df['exists']])  # Count missing images\n",
    "        if missing > 0:\n",
    "            print(f\"{name}: Missing {missing} images. First missing: {df[~df['exists']]['full_path'].iloc[0]}\")  # Print warning if missing\n",
    "        df = df[df['exists']].drop(columns=['exists'])  # Drop non-existing entries\n",
    "\n",
    "    classes = [col for col in train_df.columns if col not in ['filename', 'full_path', 'exists']]  # Extract class labels\n",
    "\n",
    "    return train_df, test_df, valid_df, classes  # Return dataframes and class names\n",
    "\n",
    "# 2. Data Generators\n",
    "def create_generators(train_df, valid_df, test_df, classes):\n",
    "    \"\"\"Create data generators using your exact paths\"\"\"\n",
    "    train_datagen = ImageDataGenerator(  # Define training data augmentation\n",
    "        rescale=1./255,  # Normalize pixel values\n",
    "        rotation_range=20,  # Randomly rotate images\n",
    "        width_shift_range=0.2,  # Random horizontal shift\n",
    "        height_shift_range=0.2,  # Random vertical shift\n",
    "        shear_range=0.2,  # Apply shearing\n",
    "        zoom_range=0.2,  # Random zoom\n",
    "        horizontal_flip=True,  # Random horizontal flip\n",
    "        fill_mode='nearest'  # Fill missing pixels\n",
    "    )\n",
    "    valtest_datagen = ImageDataGenerator(rescale=1./255)  # Validation/test data rescaling\n",
    "    train_generator = train_datagen.flow_from_dataframe(  # Create train generator\n",
    "        dataframe=train_df,\n",
    "        x_col='full_path',\n",
    "        y_col=classes,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='raw',  # Use raw labels (multi-label)\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_generator = valtest_datagen.flow_from_dataframe(  # Create validation generator\n",
    "        dataframe=valid_df,\n",
    "        x_col='full_path',\n",
    "        y_col=classes,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='raw',\n",
    "        shuffle=False\n",
    "    )\n",
    "    test_generator = valtest_datagen.flow_from_dataframe(  # Create test generator\n",
    "        dataframe=test_df,\n",
    "        x_col='full_path',\n",
    "        y_col=classes,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='raw',\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_generator, valid_generator, test_generator  # Return all generators\n",
    "\n",
    "# 3. Model Creation\n",
    "def create_model(num_classes):\n",
    "    \"\"\"Create and compile the model\"\"\"\n",
    "    base_model = EfficientNetB0(  # Load EfficientNetB0 base model\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "    )\n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False  # Prevent the base model layers from being updated during training\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))  # Define the input layer with the image size\n",
    "    x = base_model(inputs, training=False)  # Pass input through the base model (set training=False to keep base model frozen)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)  # Global average pooling layer\n",
    "    x = Dense(1024, activation='relu')(x)  # Dense layer with ReLU activation\n",
    "    outputs = Dense(num_classes, activation='sigmoid')(x)  # Output layer for multi-label classification\n",
    "    model = Model(inputs, outputs)  # Create model\n",
    "    model.compile(  # Compile the model\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    return model  # Return compiled model\n",
    "\n",
    "# 4. Training\n",
    "def train_model(model, train_generator, valid_generator):\n",
    "    \"\"\"Train the model with callbacks\"\"\"\n",
    "    callbacks = [  # Define training callbacks\n",
    "        EarlyStopping(monitor='val_loss', patience=5, verbose=1),  # Stop training early if no improvement\n",
    "        ModelCheckpoint(  # Save best model based on validation loss\n",
    "            MODEL_SAVE_PATH,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(  # Reduce learning rate if validation loss plateaus\n",
    "            monitor='val_loss',\n",
    "            factor=0.1,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(  # Train the model\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=len(valid_generator),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return history  # Return training history\n",
    "\n",
    "# 5. Evaluation\n",
    "def evaluate_model(model, test_generator):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    results = model.evaluate(test_generator, steps=len(test_generator))  # Evaluate on test data\n",
    "\n",
    "    print(f\"\\nTest Evaluation:\")\n",
    "    print(f\"Loss: {results[0]:.4f}\")  # Print loss\n",
    "    print(f\"Accuracy: {results[1]:.4f}\")  # Print accuracy\n",
    "    print(f\"AUC: {results[2]:.4f}\")  # Print AUC\n",
    "\n",
    "    return results  # Return results\n",
    "\n",
    "# 6. Prediction Function\n",
    "def predict_image(model, image_path, classes, threshold=0.5):\n",
    "    \"\"\"Make prediction for a single image\"\"\"\n",
    "    img = cv2.imread(image_path)  # Read image from file\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image at {image_path}\")  # Error if image can't be read\n",
    "    img = cv2.resize(img, IMG_SIZE)  # Resize image to input size\n",
    "    img = img / 255.0  # Normalize image\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    predictions = model.predict(img)[0]  # Get model predictions\n",
    "    output = {\"predictions\": {}}  # Initialize output\n",
    "    for i, class_name in enumerate(classes):  # Loop through classes\n",
    "        confidence = float(predictions[i])  # Get confidence\n",
    "        output[\"predictions\"][class_name] = {  # Store prediction\n",
    "            \"confidence\": confidence,\n",
    "            \"class_id\": i,\n",
    "            \"present\": confidence > threshold\n",
    "        }\n",
    "    return output  # Return dictionary of predictions\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")  # Notify data loading start\n",
    "\n",
    "    train_df, test_df, valid_df, classes = load_data()  # Load dataset\n",
    "\n",
    "    print(\"\\nData Summary:\")\n",
    "    print(f\"Classes: {classes}\")  # Print class labels\n",
    "    print(f\"Train samples: {len(train_df)}\")  # Number of train samples\n",
    "    print(f\"Validation samples: {len(valid_df)}\")  # Number of validation samples\n",
    "    print(f\"Test samples: {len(test_df)}\")  # Number of test samples\n",
    "\n",
    "    print(\"\\nCreating data generators...\")  # Notify generator creation\n",
    "    train_gen, valid_gen, test_gen = create_generators(train_df, valid_df, test_df, classes)  # Create generators\n",
    "\n",
    "    print(\"\\nCreating model...\")  # Notify model creation\n",
    "    model = create_model(len(classes))  # Create model\n",
    "\n",
    "    model.summary()  # Print model summary\n",
    "\n",
    "    print(\"\\nStarting training...\")  # Notify training start\n",
    "    history = train_model(model, train_gen, valid_gen)  # Train model\n",
    "\n",
    "    print(\"\\nEvaluating on test set...\")  # Notify test start\n",
    "    evaluate_model(model, test_gen)  # Evaluate model\n",
    "\n",
    "    print(f\"\\nSaving model to {MODEL_SAVE_PATH}\")  # Notify model saving\n",
    "    model.save(MODEL_SAVE_PATH)  # Save the model\n",
    "\n",
    "    sample_image = test_df.iloc[0]['full_path']  # Pick a sample image\n",
    "    print(f\"\\nMaking sample prediction for: {sample_image}\")  # Notify prediction\n",
    "\n",
    "    prediction = predict_image(model, sample_image, classes)  # Predict sample\n",
    "\n",
    "    print(\"Prediction results:\")  # Show prediction results\n",
    "    for class_name, pred in prediction[\"predictions\"].items():  # Loop through predictions\n",
    "        print(f\"{class_name}: {pred['confidence']:.2f} ({'Present' if pred['present'] else 'Absent'})\")  # Display prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec123a75",
   "metadata": {},
   "source": [
    "**Model Summary Review**\n",
    "\n",
    "• **Base Model**: I am using EfficientNetB0, which is a solid pre-trained architecture. It's frozen (non-trainable), which is good for transfer learning at initial stages.\n",
    "\n",
    "• **Trainable Params**: Only the last layers (dense, dense_1) are trainable — 1.3M params.\n",
    "\n",
    "• **Output**: Our final layer has 17 units, implying a multi-class classification problem with 17 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41239261",
   "metadata": {},
   "source": [
    "**Key Training Observations**\n",
    "| Metric         | Observation                                                       |\n",
    "| -------------- | ----------------------------------------------------------------- |\n",
    "| `accuracy`     | Very low — stays around 0.01–0.17 during first 6 epochs.          |\n",
    "| `val_accuracy` | Even worse — stuck around 0.12 or even drops to 0.02.             |\n",
    "| `auc`          | Improving well from 0.58 → 0.84, both in training and validation. |\n",
    "| `loss`         | Decreasing nicely — from 0.65 → 0.31 across epochs.               |\n",
    "| `val_loss`     | Also decreasing — a positive sign for generalization.             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa3b50",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "• The model is learning: Both loss and AUC are improving significantly.\n",
    "\n",
    "• However, accuracy is very low, which may be caused by:\n",
    "\n",
    "**1. Label imbalance:** Some classes might dominate; accuracy fails in such cases.\n",
    "\n",
    "**2. Multi-label confusion:** Are our labels multi-class (only one label per image) or multi-label (multiple labels per image)? If it's multi-label, you shouldn't use accuracy as-is.\n",
    "\n",
    "**3. Incorrect label encoding:** One-hot vs. integer labels — this must match your loss function.\n",
    "\n",
    "**4. Wrong loss:** Are you using categorical_crossentropy or sparse_categorical_crossentropy? It must match your label format.\n",
    "\n",
    "**5. Small dataset:** Only 8 training steps per epoch hints that your dataset may be very small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62cd152",
   "metadata": {},
   "source": [
    "**Suggestions**\n",
    "\n",
    "1. **Check our label format:**\n",
    "\n",
    "     • If labels are integers: Use sparse_categorical_crossentropy.\n",
    "\n",
    "     • If labels are one-hot vectors: Use categorical_crossentropy.\n",
    "\n",
    "2. **Use appropriate metrics:**\n",
    "\n",
    "     • For imbalanced data, use AUC, F1-score, or balanced_accuracy, not just accuracy.\n",
    "\n",
    "3. **Unfreeze EfficientNetB0 later:**\n",
    "\n",
    "     • After a few epochs, consider unfreezing part of EfficientNet to fine-tune on your data.\n",
    "\n",
    "4. **Use class weights:**\n",
    "\n",
    "     • If class imbalance exists, compute and pass class_weight to model.fit(...).\n",
    "\n",
    "5. **Try data augmentation:**\n",
    "\n",
    "     • Add rotation, zoom, flip, etc., to help generalize better.\n",
    "\n",
    "6. **Track confusion matrix:**\n",
    "\n",
    "     • To debug misclassifications, especially for underperforming classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5be72",
   "metadata": {},
   "source": [
    "**Diabetic Retinopathy Prediction Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2769168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\n",
      "Prediction results for 25_jpg.rf.087bb47fe927b1ea14a8d4cc64c4f90c.jpg:\n",
      "Most likely condition: Soft Cotton Wool (confidence: 49.56%)\n",
      "\n",
      "Detailed predictions:\n",
      "- Advanced            : 45.36% (absent)\n",
      "- Cotton Wool Spot    : 35.88% (absent)\n",
      "- Hard Exudates       : 47.16% (absent)\n",
      "- Hemorrhages         : 45.63% (absent)\n",
      "- Micro-aneurysms     : 49.31% (absent)\n",
      "- Moderate            : 37.16% (absent)\n",
      "- Moderate DR         : 43.66% (absent)\n",
      "- NPDR                : 41.16% (absent)\n",
      "- No DR               : 43.67% (absent)\n",
      "- PDR                 : 46.58% (absent)\n",
      "- Severe              : 39.53% (absent)\n",
      "- Severe DR           : 36.03% (absent)\n",
      "- Soft Cotton Wool    : 49.56% (absent)\n",
      "- Soft Exudates       : 48.83% (absent)\n",
      "- Very                : 34.55% (absent)\n",
      "- hemorrhages         : 36.54% (absent)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os  # For interacting with the file system (checking file existence, extracting file name)\n",
    "import cv2  # OpenCV library for image processing (reading, resizing images)\n",
    "import numpy as np  # NumPy for numerical operations (like image normalization, reshaping)\n",
    "from tensorflow.keras.models import load_model  # TensorFlow Keras to load the trained model\n",
    "\n",
    "# 1. Load your saved model\n",
    "model_path = r\"C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic_retinopathy_app\\diabetic_retinopathy_app\\model\\diabetic_retinopathy_model.h5\"  # Path to the trained model file\n",
    "model = load_model(model_path)  # Load the trained Keras model from disk into the model variable\n",
    "\n",
    "# 2. Define your classes (must match the class order used during model training)\n",
    "classes = [\n",
    "    'Advanced', 'Cotton Wool Spot', 'Hard Exudates', 'Hemorrhages',\n",
    "    'Micro-aneurysms', 'Moderate', 'Moderate DR', 'NPDR',\n",
    "    'No DR', 'PDR', 'Severe', 'Severe DR', 'Soft Cotton Wool',\n",
    "    'Soft Exudates', 'Very', 'hemorrhages'\n",
    "]  # The class labels are defined in the same order as in the model training\n",
    "\n",
    "# 3. Set the image size used during model training\n",
    "IMG_SIZE = (224, 224)  # The input size expected by the model (e.g., 224x224)\n",
    "\n",
    "# 4. Define the prediction function for diabetic retinopathy prediction\n",
    "def predict_diabetic_retinopathy(image_path, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict diabetic retinopathy conditions from an image.\n",
    "    Args:\n",
    "        image_path: Path to the retinal image\n",
    "        confidence_threshold: Minimum confidence threshold for labeling a condition as present (0-1)\n",
    "    Returns:\n",
    "        Dictionary with prediction results for each condition\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the image file exists\n",
    "    if not os.path.exists(image_path):  # Ensure the image path is valid and the file exists\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")  # Raise an error if the image is not found\n",
    "\n",
    "    # Load the image using OpenCV\n",
    "    img = cv2.imread(image_path)  # Read the image at the specified path\n",
    "    if img is None:  # Check if OpenCV was able to load the image\n",
    "        raise ValueError(f\"Could not read image at {image_path}\")  # Raise an error if the image could not be loaded\n",
    "\n",
    "    # Resize and preprocess the image to match model's input size\n",
    "    img = cv2.resize(img, IMG_SIZE)  # Resize the image to the model's required input size\n",
    "    img = img / 255.0  # Normalize pixel values to the range [0, 1] (scaling)\n",
    "    img = np.expand_dims(img, axis=0)  # Add a batch dimension to match the model's input shape (e.g., [1, height, width, channels])\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    predictions = model.predict(img)[0]  # Get predictions for the single image (since batch size is 1)\n",
    "\n",
    "    # Prepare a dictionary to store results\n",
    "    results = {\n",
    "        \"image\": os.path.basename(image_path),  # Extracts the image file name from the full path\n",
    "        \"predictions\": {},  # Dictionary to store predictions for each condition\n",
    "        \"summary\": {  # Summary of the most likely condition and highest confidence\n",
    "            \"most_likely_condition\": None,\n",
    "            \"highest_confidence\": 0.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Iterate over the classes and store prediction results for each\n",
    "    for class_name, confidence in zip(classes, predictions):  # Zip pairs class names with corresponding confidence values\n",
    "        is_present = confidence > confidence_threshold  # Determine if the condition is present based on the threshold\n",
    "        results[\"predictions\"][class_name] = {  # Store confidence and presence status for each condition\n",
    "            \"confidence\": float(confidence),  # Store confidence value as a float\n",
    "            \"present\": is_present  # Boolean indicating if the condition is present\n",
    "        }\n",
    "        # Track the most likely condition (highest confidence)\n",
    "        if confidence > results[\"summary\"][\"highest_confidence\"]:\n",
    "            results[\"summary\"][\"highest_confidence\"] = confidence  # Update highest confidence score\n",
    "            results[\"summary\"][\"most_likely_condition\"] = class_name  # Update the most likely condition\n",
    "\n",
    "    return results  # Return the final results dictionary with predictions\n",
    "\n",
    "# 5. Example usage with an image path\n",
    "test_image_path = r\"C:\\Users\\narra\\OneDrive\\Desktop\\My personal Files\\MY projects\\diabetic\\DIABETIC-RETINOPATHY-1\\train\\25_jpg.rf.087bb47fe927b1ea14a8d4cc64c4f90c.jpg\"  # Path to the test image for prediction\n",
    "\n",
    "# Get prediction results for the image\n",
    "results = predict_diabetic_retinopathy(test_image_path)  # Call the prediction function with the test image path\n",
    "\n",
    "# Display the summary of the most likely condition\n",
    "print(f\"\\nPrediction results for {results['image']}:\")  # Print the image file name\n",
    "print(f\"Most likely condition: {results['summary']['most_likely_condition']} \"\n",
    "      f\"(confidence: {results['summary']['highest_confidence'] * 100:.2f}%)\")  # Print the most likely condition and its confidence percentage\n",
    "\n",
    "# Display detailed predictions for all conditions\n",
    "print(\"\\nDetailed predictions:\")\n",
    "for condition, data in results[\"predictions\"].items():  # Iterate over each condition and its associated prediction data\n",
    "    status = \"present\" if data[\"present\"] else \"absent\"  # Determine if the condition is present based on confidence threshold\n",
    "    print(f\"- {condition:20}: {data['confidence'] * 100:.2f}% ({status})\")  # Print each condition with confidence and presence status\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
